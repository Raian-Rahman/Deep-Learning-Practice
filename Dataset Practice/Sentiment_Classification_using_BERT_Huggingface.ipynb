{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Classification using BERT Huggingface.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "c2r-WruvXZ7d",
        "59WdsbAmHZ0D"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYsgMHV4chQxYkuFZQKQk6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ffbcb87ec104f698589bb2164cce7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_243917338aa14495a36bbc0448485f5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6867e572f80f435d803f768325e63533",
              "IPY_MODEL_fb1d1273966e40019185c2435b329d1f"
            ]
          }
        },
        "243917338aa14495a36bbc0448485f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6867e572f80f435d803f768325e63533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16321d856f064b6dbc279f45d92540a0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afab58841cc64b99a1e653c2c5f3c7f3"
          }
        },
        "fb1d1273966e40019185c2435b329d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_708f68ff1891432abc4918bcdb8096a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:05&lt;00:00, 40.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65412bd898084c2aadbe8457beac85f8"
          }
        },
        "16321d856f064b6dbc279f45d92540a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afab58841cc64b99a1e653c2c5f3c7f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "708f68ff1891432abc4918bcdb8096a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65412bd898084c2aadbe8457beac85f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e91b9ceb42374c1b8488412d51addf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b65a21adeb554ba1920aaf3267e279ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0036f1c093a04e37abb579c811018b11",
              "IPY_MODEL_fada156317744c3a8e94cef02fe55f64"
            ]
          }
        },
        "b65a21adeb554ba1920aaf3267e279ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0036f1c093a04e37abb579c811018b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f34ae575324b4ce69b2f6d0e4e2cd6c9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dc9ab9b280243f58585838fab698de0"
          }
        },
        "fada156317744c3a8e94cef02fe55f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd8e818f1dd545b483e86015a2131ec5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:01&lt;00:00, 24.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab2fbd47e92f46459289a5e46082056f"
          }
        },
        "f34ae575324b4ce69b2f6d0e4e2cd6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dc9ab9b280243f58585838fab698de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd8e818f1dd545b483e86015a2131ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab2fbd47e92f46459289a5e46082056f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dec0f48858645c4adef43820a87011d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd6d7c460f274172aaaded53d1ee7ab0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_466f380be44d4d0e9706b6b68546894a",
              "IPY_MODEL_99598c55ebc645849e09fdc68c2f1ca3"
            ]
          }
        },
        "fd6d7c460f274172aaaded53d1ee7ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "466f380be44d4d0e9706b6b68546894a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f1ef6de889a645628bc9925ea0f7c1ef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52b7c3a104ed4b30b1d955629dd42312"
          }
        },
        "99598c55ebc645849e09fdc68c2f1ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acddc75ccaad47118c0b01b1ec47783c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 473kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a330608fa8e433fb7c0b16f0b980b71"
          }
        },
        "f1ef6de889a645628bc9925ea0f7c1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52b7c3a104ed4b30b1d955629dd42312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acddc75ccaad47118c0b01b1ec47783c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a330608fa8e433fb7c0b16f0b980b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51ca06a830ab48b3b73cc579e3be493d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_35508ed97c11462482b92b2415faff77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2161df8301a4424884c09719c9e22e97",
              "IPY_MODEL_c0db0aae49984e9bb92ef13d0a1f2dfb"
            ]
          }
        },
        "35508ed97c11462482b92b2415faff77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2161df8301a4424884c09719c9e22e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d5b772279854800a407d8786f5f7642",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b32cea8f30b8463da377f7c9c6fe6478"
          }
        },
        "c0db0aae49984e9bb92ef13d0a1f2dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea3ccb022431483e949117c14eb944bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 654B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_008bf9d8ea8f498f98c77abc8c4d8d88"
          }
        },
        "0d5b772279854800a407d8786f5f7642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b32cea8f30b8463da377f7c9c6fe6478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea3ccb022431483e949117c14eb944bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "008bf9d8ea8f498f98c77abc8c4d8d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70f89f2a9683412685c682d6676d0819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fac509c529b345489709f391255b1051",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45028b99ba344eed8907724221fd2656",
              "IPY_MODEL_81ad214ad43248ba9adffa60c6238145"
            ]
          }
        },
        "fac509c529b345489709f391255b1051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45028b99ba344eed8907724221fd2656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b3cc6da35c04ffd9d5d804537db6760",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d16ba635babf4f42a631f3f870465721"
          }
        },
        "81ad214ad43248ba9adffa60c6238145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87eb0165b686402fa62483a14bcd76b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:08&lt;00:00, 49.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3078c724a47e4c9589796d954d42495d"
          }
        },
        "9b3cc6da35c04ffd9d5d804537db6760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d16ba635babf4f42a631f3f870465721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87eb0165b686402fa62483a14bcd76b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3078c724a47e4c9589796d954d42495d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raian-Rahman/Deep-Learning-Practice/blob/main/Sentiment_Classification_using_BERT_Huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQIaIzPAXJ17"
      },
      "source": [
        "# Overview\n",
        "\n",
        "Generally we can't simply use send a sequence of text into a neural network. Before sending it to neural network, we need to explore the dataset, tokenize the sequences, preprocess the data, add masking and padding and then send the vectors to the network. In this notebook we are going to see how text preprocessing can be done using huggingface library. \\\\\n",
        "The notebook was developed using different resources. I followed a Youtube video by [Venelin Valkov](https://www.youtube.com/watch?v=Osj0Z6rwJB4)\n",
        "\n",
        "#### Author Details\n",
        "Raian Rahman \\\\\n",
        "Dept. of Computer Science and Engineering \\\\\n",
        "Islamic University of Technology \\\\\n",
        "Gazipur, Dhaka\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEoQ04gKYaDZ"
      },
      "source": [
        "# Environment Setup\n",
        "## Installing transfomers \n",
        "To use the huggingface library, first we need to install ```transformers``` library using pip install. It installs the ```tokenizers```, ```sacremoses```, ```transformers```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J247AbqW1C3",
        "outputId": "ae6f1b96-100d-4c03-9d04-d6b132743184"
      },
      "source": [
        "!pip install transformers sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 4.3MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 49.8MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb5bbA8XY2bi"
      },
      "source": [
        "## Importing the necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xdgURaFYoqc"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import sentencepiece\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRJcqCf0a51y"
      },
      "source": [
        "# Exploring the dataset\n",
        "## Reading the dataset\n",
        "In this subsection we will be reading the dataset. We are using pandas ```read_csv``` library to work with the dataset. \\\\\n",
        "We are using SST2 dataset for our research "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oLPVZTZ3af_z",
        "outputId": "d2cd6f1f-cd54-41a0-8975-b4467dcb3d45"
      },
      "source": [
        "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  a stirring , funny and finally transporting re...  1\n",
              "1  apparently reassembled from the cutting room f...  0\n",
              "2  they presume their audience wo n't sit still f...  0\n",
              "3  this is a visually stunning rumination on love...  1\n",
              "4  jonathan parker 's bartleby should have been t...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdliYjuFbOak",
        "outputId": "a6d7d03c-1579-4f83-f5a4-07ad2cd9a3fc"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6920, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBEw8TDxbbe7",
        "outputId": "5b3473eb-9694-4faf-f74d-47dc72e68c8d"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6920 entries, 0 to 6919\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       6920 non-null   object\n",
            " 1   1       6920 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 108.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "SXvfVJ2hbeEy",
        "outputId": "18daa39a-31cc-462f-c075-d70ac11da4a1"
      },
      "source": [
        "sns.countplot(df[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f735d05bb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 745,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PHxZMRujcLm7",
        "outputId": "4ac631ab-a3aa-4633-d294-39b6e91e3dd1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  a stirring , funny and finally transporting re...  1\n",
              "1  apparently reassembled from the cutting room f...  0\n",
              "2  they presume their audience wo n't sit still f...  0\n",
              "3  this is a visually stunning rumination on love...  1\n",
              "4  jonathan parker 's bartleby should have been t...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJOD8SSlcivq"
      },
      "source": [
        "## Data Preprocessing\n",
        "First, we are going to use the tokenizer for the huggingface library. We need bert tokenizer for some special cases. These are:\n",
        "- BERT requires some special tokens for processing. Like \\<cls\\> for classification and \\<sep\\> for seperating the sentences. \n",
        "- We will need to do some padding\n",
        "- We need to create the attention mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5hvFTwmcZKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "0ffbcb87ec104f698589bb2164cce7a9",
            "243917338aa14495a36bbc0448485f5e",
            "6867e572f80f435d803f768325e63533",
            "fb1d1273966e40019185c2435b329d1f",
            "16321d856f064b6dbc279f45d92540a0",
            "afab58841cc64b99a1e653c2c5f3c7f3",
            "708f68ff1891432abc4918bcdb8096a9",
            "65412bd898084c2aadbe8457beac85f8",
            "e91b9ceb42374c1b8488412d51addf30",
            "b65a21adeb554ba1920aaf3267e279ee",
            "0036f1c093a04e37abb579c811018b11",
            "fada156317744c3a8e94cef02fe55f64",
            "f34ae575324b4ce69b2f6d0e4e2cd6c9",
            "7dc9ab9b280243f58585838fab698de0",
            "fd8e818f1dd545b483e86015a2131ec5",
            "ab2fbd47e92f46459289a5e46082056f",
            "3dec0f48858645c4adef43820a87011d",
            "fd6d7c460f274172aaaded53d1ee7ab0",
            "466f380be44d4d0e9706b6b68546894a",
            "99598c55ebc645849e09fdc68c2f1ca3",
            "f1ef6de889a645628bc9925ea0f7c1ef",
            "52b7c3a104ed4b30b1d955629dd42312",
            "acddc75ccaad47118c0b01b1ec47783c",
            "8a330608fa8e433fb7c0b16f0b980b71"
          ]
        },
        "outputId": "064769d8-73ed-48ee-cb63-5925d275c1ad"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ffbcb87ec104f698589bb2164cce7a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e91b9ceb42374c1b8488412d51addf30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dec0f48858645c4adef43820a87011d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAM3_feexwTg"
      },
      "source": [
        "## Special Token\n",
        "For BERT training we need three different tokens. \n",
        "- Seperation token \\<sep\\> token\n",
        "- Classification toen \\<cls\\> token\n",
        "- Padding token \\<pad\\> token\n",
        "- Unknown token \\<unk\\> token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4t65tdJThH2"
      },
      "source": [
        "## Choosing Sequence Length\n",
        "For this example, we had to design the system in such a way that the maximum length of a sequence is the maximum. The following block of code is designed to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgsHxFVcCdg1",
        "outputId": "88f2ecdd-9cee-4814-85a0-3d9319efbf96"
      },
      "source": [
        "sample_text ='[CLS] HuggingFace is based in NYC [SEP] Where is HuggingFace based? [SEP]'\n",
        "\n",
        "encoding = tokenizer.encode_plus(\n",
        "    tokens,\n",
        "    max_length = 32, #max length of sentence\n",
        "    add_special_tokens = True, \n",
        "    pad_to_max_length = True, \n",
        "    return_attention_mask = True,\n",
        "    return_token_type_ids = True,\n",
        "    return_tensors = 'pt'\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4XTx-y2zT0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289dc705-76bd-462b-f2c0-14bf43eaf3f4"
      },
      "source": [
        "token_len = []\n",
        "\n",
        "for text in df[0]:\n",
        "    tokens = tokenizer.encode(text, max_length=512)\n",
        "    token_len.append(len(tokens))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "axu7UF2QURRW",
        "outputId": "dc9140ae-922c-4915-a59e-f3597e900b11"
      },
      "source": [
        "sns.distplot(token_len)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f735c2994d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 749,
              "height": 471
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4iTa1a7UqwO"
      },
      "source": [
        "**From here we can see that most of the examples have less than $128$ tokens.** So, we will use $128$ tokens per example. It is mainly due to the larger the sequence the higher the training time will be. So later after training, we might increase the training size. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlOShRIeVesF"
      },
      "source": [
        "## Create a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ9F5IArUecd"
      },
      "source": [
        "class SST2Dataset(Dataset):\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNno6ht-Wj5_"
      },
      "source": [
        "MAX_LEN = 60\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG4IWpZhWtqW"
      },
      "source": [
        "df_train, df_test = train_test_split(\n",
        "  df,\n",
        "  test_size=0.1,\n",
        "  random_state=RANDOM_SEED\n",
        ")\n",
        "df_val, df_test = train_test_split(\n",
        "  df_test,\n",
        "  test_size=0.5,\n",
        "  random_state=RANDOM_SEED\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JTjNjVXN8t",
        "outputId": "453bf130-0a6e-4b7b-d7c4-efb77ab4f280"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6228, 2), (346, 2), (346, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2r-WruvXZ7d"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhilIhvGXQbF"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = SST2Dataset(\n",
        "    reviews=df[0].to_numpy(),\n",
        "    targets=df[1].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omO7cIyqXwhG",
        "outputId": "2813bc8f-95bd-4c09-bb47-0bc747b0a995"
      },
      "source": [
        "print(tokenizer)\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN,BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PreTrainedTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbb446H3YHOd",
        "outputId": "15d05d22-d6ca-4bda-9217-58228ef691b2"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaLLcldBYx0m",
        "outputId": "e8280934-26bf-4fd8-f973-4a334856fa5a"
      },
      "source": [
        "print(data['input_ids'].shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 60])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59WdsbAmHZ0D"
      },
      "source": [
        "## Initialize the BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ5bKabYZQfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "51ca06a830ab48b3b73cc579e3be493d",
            "35508ed97c11462482b92b2415faff77",
            "2161df8301a4424884c09719c9e22e97",
            "c0db0aae49984e9bb92ef13d0a1f2dfb",
            "0d5b772279854800a407d8786f5f7642",
            "b32cea8f30b8463da377f7c9c6fe6478",
            "ea3ccb022431483e949117c14eb944bc",
            "008bf9d8ea8f498f98c77abc8c4d8d88",
            "70f89f2a9683412685c682d6676d0819",
            "fac509c529b345489709f391255b1051",
            "45028b99ba344eed8907724221fd2656",
            "81ad214ad43248ba9adffa60c6238145",
            "9b3cc6da35c04ffd9d5d804537db6760",
            "d16ba635babf4f42a631f3f870465721",
            "87eb0165b686402fa62483a14bcd76b8",
            "3078c724a47e4c9589796d954d42495d"
          ]
        },
        "outputId": "a5fc6c49-b410-4d48-afcd-dcc3013f68b3"
      },
      "source": [
        "bert_model = BertModel.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51ca06a830ab48b3b73cc579e3be493d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70f89f2a9683412685c682d6676d0819",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCBv57rFJpCE"
      },
      "source": [
        "## Building a Sentiment Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xgZyi8LH_Cg"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "    self.drop = nn.Dropout(p=0.25)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      return_dict = False\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    output = self.out(output)\n",
        "\n",
        "    return self.softmax(output)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cuB507iCtys"
      },
      "source": [
        "class_names = ['negative','postive']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDbhrc_KIWHx",
        "outputId": "bb5f21fb-2e3f-4409-8848-83eea7223c24"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNJnKmNHIcWA",
        "outputId": "70bd135e-a9cd-4a0b-8493-540d9b66025c"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq lengt"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 60])\n",
            "torch.Size([16, 60])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP3NZBgGInhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad2a2ad-fb8e-4cb1-c116-74aaef96513f"
      },
      "source": [
        "model(input_ids,attention_mask)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3941, 0.6059],\n",
              "        [0.4289, 0.5711],\n",
              "        [0.5590, 0.4410],\n",
              "        [0.4506, 0.5494],\n",
              "        [0.7154, 0.2846],\n",
              "        [0.4243, 0.5757],\n",
              "        [0.4649, 0.5351],\n",
              "        [0.5385, 0.4615],\n",
              "        [0.6300, 0.3700],\n",
              "        [0.6141, 0.3859],\n",
              "        [0.5575, 0.4425],\n",
              "        [0.5994, 0.4006],\n",
              "        [0.3916, 0.6084],\n",
              "        [0.5612, 0.4388],\n",
              "        [0.5896, 0.4104],\n",
              "        [0.3001, 0.6999]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZKxVN2MEJE"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHZz5S_JMGdw"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader)*EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_steps\n",
        ")\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qapxMGOMxiA"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_function, optimizer, device, scheduler, n_examples):\n",
        "    model = model.train()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d['input_ids'].to(device)\n",
        "        attention_mask = d['attention_mask'].to(device)\n",
        "        targets = d['targets'].to(device)\n",
        "        outputs = model(\n",
        "            input_ids,\n",
        "            attention_mask\n",
        "        )\n",
        "\n",
        "        _, pred = torch.max(outputs, dim = 1)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        correct_predictions += torch.sum(pred==targets)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    return correct_predictions.double()/n_examples,np.mean(losses)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ibc8a3mlIpE"
      },
      "source": [
        "Data -> tokenizer_load -> encode -> [token_ids, attention_mask, token_type] -> token_ids, attention_mask, forward_pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0D1mttOLTpc"
      },
      "source": [
        "def eval_model(model, data_loader, loss_function, device, n_examples):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['input_ids'].to(device)\n",
        "            attention_mask = d['attention_mask'].to(device)\n",
        "            targets = d['targets'].to(device)\n",
        "            outputs = model(\n",
        "                input_ids,\n",
        "                attention_mask\n",
        "            )\n",
        "\n",
        "            _, pred = torch.max(outputs, dim = 1)\n",
        "\n",
        "            loss = loss_function(outputs, targets)\n",
        "\n",
        "            correct_predictions += torch.sum(pred==targets)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double()/n_examples,np.mean(losses)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdlz4LISOvsi",
        "outputId": "8a5d0b2e-b21c-4b0f-eeca-f0c6a30a405b"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}')\n",
        "    print('*'*25)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model, \n",
        "        train_data_loader,\n",
        "        loss_function,\n",
        "        optimizer,\n",
        "        device,\n",
        "        scheduler,\n",
        "        len(df_train)\n",
        "    )\n",
        "\n",
        "    print(f'Train loss: {train_loss} accuracy: {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader,\n",
        "        loss_function,\n",
        "        device,\n",
        "        len(df_val)\n",
        "    )\n",
        "\n",
        "    print(f'Validation loss: {val_loss} validation accuracy: {val_acc}')\n",
        "    print('')\n",
        "\n",
        "    history['train_acc'] = train_acc\n",
        "    history['train_loss'] = train_loss\n",
        "    history['val_acc'] = val_acc\n",
        "    history['val_loss'] = val_loss\n",
        "    \n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(),'model.bin')\n",
        "        best_accuracy = val_acc"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.5135922830074261 accuracy: 0.7862877328195247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4217961674386805 validation accuracy: 0.8901734104046243\n",
            "\n",
            "Epoch 2/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.41857461409691055 accuracy: 0.8924213230571612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4102519005537033 validation accuracy: 0.907514450867052\n",
            "\n",
            "Epoch 3/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3939578644740276 accuracy: 0.917951188182402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.41821699657223443 validation accuracy: 0.8959537572254335\n",
            "\n",
            "Epoch 4/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.38399467177880114 accuracy: 0.9280667951188182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.42656922475858167 validation accuracy: 0.884393063583815\n",
            "\n",
            "Epoch 5/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3655592048779512 accuracy: 0.947334617854849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4138692603869872 validation accuracy: 0.8988439306358381\n",
            "\n",
            "Epoch 6/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.36362958405262386 accuracy: 0.9492614001284521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.40430318225513806 validation accuracy: 0.9132947976878613\n",
            "\n",
            "Epoch 7/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.35920038200341736 accuracy: 0.953596660244059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.40022263066335156 validation accuracy: 0.9161849710982658\n",
            "\n",
            "Epoch 8/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3570082397797169 accuracy: 0.9561657032755299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.38290706276893616 validation accuracy: 0.9335260115606936\n",
            "\n",
            "Epoch 9/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.35715690897061275 accuracy: 0.955684007707129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4036244221708991 validation accuracy: 0.907514450867052\n",
            "\n",
            "Epoch 10/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3499167968065311 accuracy: 0.9629094412331406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3863663063807921 validation accuracy: 0.9306358381502889\n",
            "\n",
            "Epoch 11/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3458131580780714 accuracy: 0.9670841361592806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3988283588127656 validation accuracy: 0.9132947976878613\n",
            "\n",
            "Epoch 12/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.342413472594359 accuracy: 0.9706165703275529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39631675454703247 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 13/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3436936802588976 accuracy: 0.9691714836223506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4013767594640905 validation accuracy: 0.9132947976878613\n",
            "\n",
            "Epoch 14/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3407390220042987 accuracy: 0.972382787411689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3959909880703146 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 15/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33830760434651985 accuracy: 0.974791265253693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.38682983815670013 validation accuracy: 0.9277456647398844\n",
            "\n",
            "Epoch 16/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3374223528764187 accuracy: 0.9757546563904945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4078669006174261 validation accuracy: 0.907514450867052\n",
            "\n",
            "Epoch 17/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33908482858767874 accuracy: 0.9741490044958252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3923543014309623 validation accuracy: 0.9219653179190751\n",
            "\n",
            "Epoch 18/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3358010363884461 accuracy: 0.9773603082851637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.389707087115808 validation accuracy: 0.9219653179190751\n",
            "\n",
            "Epoch 19/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33684671238446845 accuracy: 0.9762363519588952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3885740475221114 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 20/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.334750389899963 accuracy: 0.9784842646114321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.37740764157338574 validation accuracy: 0.9364161849710982\n",
            "\n",
            "Epoch 21/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3342366222387705 accuracy: 0.978965960179833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39825133031064813 validation accuracy: 0.9161849710982658\n",
            "\n",
            "Epoch 22/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33286832509896697 accuracy: 0.9804110468850352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3750769848173315 validation accuracy: 0.9393063583815029\n",
            "\n",
            "Epoch 23/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33504179486861596 accuracy: 0.9781631342324983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.396080573851412 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 24/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33500425632183367 accuracy: 0.9781631342324983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.38867924972013995 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 25/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33679104286890765 accuracy: 0.9763969171483622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3853849849917672 validation accuracy: 0.9306358381502889\n",
            "\n",
            "Epoch 26/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3342536081106235 accuracy: 0.978965960179833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3921918435530229 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 27/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3351801085166442 accuracy: 0.9780025690430314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39177714017304505 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 28/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3330676324092425 accuracy: 0.9800899165061014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39245090294968 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 29/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33228659752087714 accuracy: 0.980892742453436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39511063965884125 validation accuracy: 0.9219653179190751\n",
            "\n",
            "Epoch 30/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3333042677396383 accuracy: 0.9799293513166345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3932682749899951 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 31/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33224412623124244 accuracy: 0.981053307642903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4018413763154637 validation accuracy: 0.9161849710982658\n",
            "\n",
            "Epoch 32/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3326779762139687 accuracy: 0.9804110468850352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39778639511628583 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 33/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33287497361501056 accuracy: 0.9802504816955684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39757488667964935 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 34/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33213001787662505 accuracy: 0.981053307642903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3885586153377186 validation accuracy: 0.9277456647398844\n",
            "\n",
            "Epoch 35/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33177015284697214 accuracy: 0.9813744380218368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3889923176982186 validation accuracy: 0.9277456647398844\n",
            "\n",
            "Epoch 36/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3312099996285561 accuracy: 0.9820166987797045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39179483868859033 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 37/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3315458507109911 accuracy: 0.9816955684007707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3910773179747842 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 38/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3316867264417502 accuracy: 0.9815350032113037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3893868178129196 validation accuracy: 0.9277456647398844\n",
            "\n",
            "Epoch 39/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.33040974224225067 accuracy: 0.9828195247270392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3922381658445705 validation accuracy: 0.9219653179190751\n",
            "\n",
            "Epoch 40/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3301330324931022 accuracy: 0.9831406551059729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39772494679147546 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 41/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3306749638074484 accuracy: 0.9824983943481053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4000102389942516 validation accuracy: 0.9161849710982658\n",
            "\n",
            "Epoch 42/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3297745824624331 accuracy: 0.9834617854849068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39623284204439685 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 43/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.329607802323806 accuracy: 0.9836223506743738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3918230181390589 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 44/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3300625043801772 accuracy: 0.9831406551059729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.40295923162590375 validation accuracy: 0.9132947976878613\n",
            "\n",
            "Epoch 45/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3298039185695159 accuracy: 0.9834617854849068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3922168693759225 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 46/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.32944784538868144 accuracy: 0.9837829158638407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.390835775570436 validation accuracy: 0.9248554913294798\n",
            "\n",
            "Epoch 47/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.329661669028111 accuracy: 0.9836223506743738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3956299911845814 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 48/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3292875463381792 accuracy: 0.9839434810533075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3952748585831035 validation accuracy: 0.9190751445086704\n",
            "\n",
            "Epoch 49/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.3294020787263528 accuracy: 0.9837829158638407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.38954021443020215 validation accuracy: 0.9277456647398844\n",
            "\n",
            "Epoch 50/50\n",
            "*************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.32944762744964695 accuracy: 0.9837829158638407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3871025768193332 validation accuracy: 0.9306358381502889\n",
            "\n",
            "CPU times: user 38min 47s, sys: 21 s, total: 39min 8s\n",
            "Wall time: 39min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlHobnNSFBqj"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO-W7pWzFDbL"
      },
      "source": [
        "#### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu6fS1mfFDNz"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model.load_state_dict(torch.load('model.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfJPjqe5PRoS"
      },
      "source": [
        "def get_reviews(model, data_loader):\n",
        "    model = model.eval()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}